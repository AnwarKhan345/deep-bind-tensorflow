{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepBind.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tBaMjU_B34FS",
        "colab_type": "code",
        "outputId": "d2fa2456-32f3-455b-feb6-4f76db043622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2366
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " 10080856425781790874.xlsx\n",
            "'AMC 10 Contest Form Number 6.pdf'\n",
            "'AMC 10 Contest Form Number 6.pdf.gdoc'\n",
            "'APA Reference List Concussion Presentation.gdoc'\n",
            "'Article English Culminating Seyone.gdoc'\n",
            "'article .gdoc'\n",
            "'Article response .gdoc'\n",
            "'Book Talk.gdoc'\n",
            "'Book Talk Week 2: The Chrysalids.gdoc'\n",
            "'butter cake smh.gdoc'\n",
            "'Careers - ICS 3U Assignment.gdoc'\n",
            " CCIHE2015-PublicDataFile.gsheet\n",
            " CCIHE2015-PublicDataFile.xlsx\n",
            " Classroom\n",
            "'Climate Change Project - New York'\n",
            "'CMA Sponsorship Email.gdoc'\n",
            "'Colab Notebooks'\n",
            "'COMC Contest Form Number 14.pdf'\n",
            "'Computer History.gdoc'\n",
            "'Concert Report- Seyone Chithrananda.gdoc'\n",
            "'Consumer Product Research Project'\n",
            "'Copy of PPT TEMPLATE - Walmart Challenge Deck.gslides'\n",
            "'Copy of Transition Meeting Agenda - 22 06 18.gdoc'\n",
            "'DECA 2k19'\n",
            "'DECA Execs 18-19'\n",
            "'Duties for Sponsorship.gdoc'\n",
            "'Electricity Circuit Assignment Writeup.gdoc'\n",
            "'english grade 9'\n",
            "'English Trade in Venicew'\n",
            "'Environment vs. Economy Speech.docx'\n",
            "'Environment vs. Economy Speech.docx.gdoc'\n",
            " EquiTrade.zip\n",
            " FactSheetSeyonePeterTransportation.pdf\n",
            "'FinalVideo (1).mp4'\n",
            " FinalVideo.mp4\n",
            "'For thousands of years, people of minorities and marginalized groups have felt imprisoned from the opportunities they deserve, simply due to the color of their skin.gdoc'\n",
            " Freshii.gdoc\n",
            "'General presentation.gslides'\n",
            "'geo culm. task '\n",
            " History\n",
            "'hosa biomed'\n",
            " ICS3U\n",
            " IMG_2724.TRIM.MOV\n",
            " IMG_2727.TRIM.MOV\n",
            " IMG-2864.JPG\n",
            " IMG_2911.TRIM.MOV\n",
            "'Interview Response: Defining Moments in My History.gdoc'\n",
            "'JEC 2018 Application - Seyone Chithrananda.gdoc'\n",
            "'Journal Book talk #2 (1).gdoc'\n",
            "'Journal Book talk #2.docx'\n",
            "'Journal Book talk #2.gdoc'\n",
            "'Journal Week 1 Book Talk.gdoc'\n",
            " Kumon_ResumeSeyone.gdoc\n",
            "'La tâche finale - unité 2.gdoc'\n",
            "'Leo Andrey Seyone.doc'\n",
            "'Leo Andrey Seyone.gdoc'\n",
            " mathematica\n",
            "'MedApplications email.gdoc'\n",
            " Methods.txt\n",
            "'MOV Essay.gdoc'\n",
            "'MSC 2018-2019'\n",
            "'News Report.gdoc'\n",
            "'NYC was the first-ever city plan to meet the goals of the Paris Climate agreement in June of 2017, setting a new precedent for city-wide climate change reform.gdoc'\n",
            "'OMS Bio - Seyone.gdoc'\n",
            "'OMS Toronto 2019'\n",
            "'Ophthalmology by Seyone.doc'\n",
            "'Ophthalmology by Seyone.gdoc'\n",
            "'Ophthalmology by Seyone.pdf'\n",
            "'Paper Recommendations_CRISPR.gdoc'\n",
            "'Peter Dinklage.gdoc'\n",
            "'Politcal Correctness Speech.gdoc'\n",
            "'Princeton Review Email.gdoc'\n",
            "'procedure list.gdoc'\n",
            "'Rangle Article-feel free to make edits!.gdoc'\n",
            "'Rangle Article.gdoc'\n",
            "'RBC Sponsorship Email.gdoc'\n",
            "'Reading Assignment #3.gdoc'\n",
            "'Reading Assignment 6.gdoc'\n",
            "'references for lecce job.gdoc'\n",
            " Report.gdoc\n",
            "'research ops.gdoc'\n",
            "'Resume (1).gdoc'\n",
            " Resume_Computer_Science.pdf\n",
            " Resume.gdoc\n",
            " Resume.pdf\n",
            " ResumeSeyone.gdoc\n",
            "'rita sucks.gdoc'\n",
            "'Safari - Oct 3, 2018 at 11:14 AM.pdf'\n",
            "'Safari - Sep 24, 2018 at 8:33 AM.pdf'\n",
            "'Schedule for NYC Trip.gdoc'\n",
            "'Senegal French Unit 2 Project.gslides'\n",
            " Seyone_Chithrananda_C1_HW\n",
            "'Seyone Chithrananda, Viability Draft Awareness Post.gdoc'\n",
            "'Seyone, Study Sheet.gdoc'\n",
            "'Seyone_Supplementary Application 2018-2019.gdoc'\n",
            " StringAssignment.java\n",
            "'Summary: The Open Window Grade 9 English.gdoc'\n",
            " Tasks.gdoc\n",
            "'TB Page 95 reponses biology 10.gdoc'\n",
            "'The Art of Teaching Machines to Learn.gdoc'\n",
            "'The End of Liberal Power.gdoc'\n",
            "'The Rohingya Crisis in Myanmar.gdoc'\n",
            "'TKS 2019'\n",
            "'tks personal'\n",
            "'TMLS Scholarship Application.gdoc'\n",
            "'Transportation in canada.pptx'\n",
            "'Untitled document (10).gdoc'\n",
            "'Untitled document (11).gdoc'\n",
            "'Untitled document (12).gdoc'\n",
            "'Untitled document (13).gdoc'\n",
            "'Untitled document (14).gdoc'\n",
            "'Untitled document (15).gdoc'\n",
            "'Untitled document (16).gdoc'\n",
            "'Untitled document (17).gdoc'\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document (2).gdoc'\n",
            "'Untitled document (3).gdoc'\n",
            "'Untitled document (4).gdoc'\n",
            "'Untitled document (5).gdoc'\n",
            "'Untitled document (6).gdoc'\n",
            "'Untitled document (7).gdoc'\n",
            "'Untitled document (8).gdoc'\n",
            "'Untitled document (9).gdoc'\n",
            "'Untitled document.gdoc'\n",
            "'Untitled drawing.gdraw'\n",
            "'Untitled map.gmap'\n",
            "'Untitled presentation (1).gslides'\n",
            "'Untitled presentation.gslides'\n",
            " Viability\n",
            "'Vision Board.gdraw'\n",
            "'Volunteer Info.gsheet'\n",
            "'WesternU Medicine Email.gdoc'\n",
            "\"Why it's great to be Canada.gdoc\"\n",
            " Ya.gdoc\n",
            "'YorkU Helix Email.gdoc'\n",
            "'Your big idea.gslides'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fv_v3ItK8DdW",
        "colab_type": "code",
        "outputId": "d4b9b8ae-7c04-46a4-e587-9fb7e8704138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/replicate 2 /\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DeepBind.ipynb\tnbt.3300-S6.gsheet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BmIePJXF8H9D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import csv\n",
        "import math \n",
        "import random\n",
        "import gzip\n",
        "from scipy.stats import bernoulli\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IPUAalsQ96TM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nummotif=16 #number of motifs to discover\n",
        "bases='ACGT' #DNA bases\n",
        "basesRNA='ACGU'#RNA bases\n",
        "batch_size=64 #fixed batch size -> see notes to problem about it\n",
        "dictReverse={'A':'T','C':'G','G':'C','T':'A','N':'N'} #dictionary to implement reverse-complement mode\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7BeQjNYI-LQf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class Experiment:\n",
        "    def __init__(self,filename,motiflen):\n",
        "        self.file=filename\n",
        "        self.motiflen=motiflen\n",
        "    \n",
        "    def getMotifLen(self):\n",
        "        return self.motiflen\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AkL45sKb-LMG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pads sequence \n",
        "def seqtopad(sequence,motlen,kind='DNA'):\n",
        "    rows=len(sequence)+2*motlen-2\n",
        "    S=np.empty([rows,4])\n",
        "    base= bases if kind=='DNA' else basesRNA\n",
        "    for i in range(rows):\n",
        "        for j in range(4):\n",
        "            if i-motlen+1<len(sequence) and sequence[i-motlen+1]=='N' or i<motlen-1 or i>len(sequence)+motlen-2:\n",
        "                S[i,j]=np.float32(0.25)\n",
        "            elif sequence[i-motlen+1]==base[j]:\n",
        "                S[i,j]=np.float32(1)\n",
        "            else:\n",
        "                S[i,j]=np.float32(0)\n",
        "    return S\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6n0xqaFP-Rex",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# shuffles sequence\n",
        "def dinucshuffle(sequence):\n",
        "    b=[sequence[i:i+2] for i in range(0, len(sequence), 2)]\n",
        "    random.shuffle(b)\n",
        "    d=''.join([str(x) for x in b])\n",
        "    return d\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tu5eQt5L-TmH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# generates real number in some interval, (a, b)\n",
        "def logsampler(a,b):\n",
        "    x=tf.Variable(tf.random_uniform([],minval=0,maxval=1), trainable=False)\n",
        "    y=10**((math.log10(b)-math.log10(a))*x + math.log10(a))\n",
        "    \n",
        "#     x=np.random.uniform(low=0,high=1)\n",
        "#     y=10**((math.log10(b)-math.log10(a))*x + math.log10(a))\n",
        "    return y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aoyj5thS-WcP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# generates real number in some interval, less aggressively skewed towards b\n",
        "def sqrtsampler(a,b):\n",
        "    x=tf.Variable(tf.random_uniform([],minval=0,maxval=1), trainable=False)\n",
        "#     x=np.random.uniform(low=0,high=1)\n",
        "    y=(b-a)*(x**0.5)+a\n",
        "    return y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nOAD7HAZ-fgU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# processes ChIP-seq data\n",
        "class Chip(Experiment):\n",
        "    def __init__(self,filename,motiflen=24):\n",
        "        self.file = filename\n",
        "        self.motiflen = motiflen\n",
        "            \n",
        "    def openFile(self):\n",
        "        train_dataset=[]\n",
        "     \n",
        "        with gzip.open(self.file, 'rt') as data:\n",
        "            next(data)\n",
        "            reader = csv.reader(data,delimiter='\\t')\n",
        "            \n",
        "            for row in reader:\n",
        "                    train_dataset.append([seqtopad(row[2],self.motiflen),[1]])\n",
        "                    \n",
        "                    train_dataset.append([seqtopad(dinucshuffle(row[2]),self.motiflen),[0]])\n",
        "                   \n",
        "        \n",
        "        \n",
        "        random.shuffle(train_dataset)\n",
        "        frac1=int(len(train_dataset)*1/3)\n",
        "        frac2=int(len(train_dataset)*2/3)\n",
        "        return train_dataset[:frac1],train_dataset[frac1:frac2],train_dataset[frac2:],train_dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FBnO55GN-hrG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename='/content/drive/My Drive/replicate 2 /ELK1_GM12878_ELK1_(1277-1)_Stanford_AC.seq.gz'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I7d_KQSn_R8o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test= Chip(filename)\n",
        "d1,d2,d3,dataAll =test.openFile()\n",
        "\n",
        "data1=np.asarray([el[0] for el in d1],dtype=np.float32)\n",
        "label1=np.asarray([el[1] for el in d1],dtype=np.float32).reshape(len(data1),1)\n",
        "\n",
        "data2=np.asarray([el[0] for el in d2],dtype=np.float32)\n",
        "label2=np.asarray([el[1] for el in d2],dtype=np.float32).reshape(len(data2),1)\n",
        "\n",
        "data3=np.asarray([el[0] for el in d3],dtype=np.float32)\n",
        "label3=np.asarray([el[1] for el in d3],dtype=np.float32).reshape(len(data3),1)\n",
        "\n",
        "data=[data1,data2,data3]\n",
        "label=[label1,label2,label3]\n",
        "\n",
        "data_all=np.asarray([el[0] for el in dataAll],dtype=np.float32)\n",
        "label_all=np.asarray([el[1] for el in dataAll],dtype=np.float32).reshape(len(data_all),1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "azTWpSor_4FO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convolution(input_data, num_input_channels, num_filters, filter_shape, conv_weights,bias_weights,wd1,bd1,W,b,pooling,neuType,training,dropprob):\n",
        "\n",
        "    \n",
        "    # setup the convolutional layer operation\n",
        "    out_layer = tf.nn.conv1d(input_data, conv_weights, 1, padding='VALID')\n",
        "\n",
        "    out_layer= tf.subtract(out_layer,conv_bias)\n",
        "\n",
        "    # apply a ReLU non-linear activation\n",
        "    out_layer = tf.nn.relu(out_layer)\n",
        "\n",
        "    # now perform pooling\n",
        "    if pooling == 'max_pool':\n",
        "        pool=tf.reduce_max(out_layer,axis=1) \n",
        "        \n",
        "    elif pooling == 'avg_pool':\n",
        "        out_layer1= tf.reduce_max(out_layer, axis=1)\n",
        "        out_layer2= tf.reduce_mean(out_layer, axis=1)\n",
        "        \n",
        "        x_expanded = tf.expand_dims(out_layer1, 2)                 \n",
        "        y_expanded = tf.expand_dims(out_layer2, 2)  \n",
        "        \n",
        "        concatted = tf.concat([x_expanded, y_expanded], 2)  \n",
        "\n",
        "        pool = tf.reshape(concatted, [-1, 2*num_filters]) \n",
        "        \n",
        "\n",
        "    t =tf.constant(1 ,dtype=tf.float32)\n",
        "    \n",
        "    def ifTrain(pool):\n",
        "        pooldrop = tf.nn.dropout(pool,keep_prob=dropprob)\n",
        "#         pooldrop=tf.multiply(pool,mask) \n",
        "        out = tf.matmul(pooldrop, wd1) + bd1\n",
        "        \n",
        "        return out\n",
        "    def ifTest(pool):\n",
        "        out = dropprob*tf.matmul(pool, wd1) + bd1\n",
        "        return out\n",
        "    \n",
        "    #check if there's hidden stage\n",
        "    if(neuType=='nohidden'):\n",
        "\n",
        "        out = tf.cond(tf.equal(training,t), lambda: ifTrain(pool), lambda: ifTest(pool))\n",
        "\n",
        "        \n",
        "    elif(neuType=='hidden'):\n",
        "\n",
        "\n",
        "        dense_layer1 = tf.matmul(pool, W) + b\n",
        "        dense_layer1=tf.nn.relu(dense_layer1)\n",
        "        \n",
        "        out = tf.cond(tf.equal(training,t), lambda: ifTrain(dense_layer1), lambda: ifTest(dense_layer1))\n",
        "        \n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xYFYa99qACGj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "graph=tf.Graph()\n",
        "with graph.as_default():\n",
        "    \n",
        "    num_input_channels=4\n",
        "    num_filters=16\n",
        "    filter_shape=24\n",
        "    pooling='avg_pool'\n",
        "    neuType='nohidden'\n",
        "    \n",
        "    beta1=tf.placeholder_with_default(logsampler(10**-15,10**-3),shape=())\n",
        "    beta2=tf.placeholder_with_default(logsampler(10**-10,10**-3),shape=())\n",
        "    beta3=tf.placeholder_with_default(logsampler(10**-10,10**-3),shape=())\n",
        "\n",
        "    \n",
        "    \n",
        "    learning_rate= tf.placeholder_with_default(logsampler(0.0005, 0.05),shape=())\n",
        "    momentum_rate= tf.placeholder_with_default(sqrtsampler(0.95, 0.99),shape=())\n",
        "    \n",
        "\n",
        "    batch_size=64\n",
        "    with tf.device('/gpu:0'):\n",
        "    \n",
        "      x = tf.placeholder(tf.float32, [None, 147, 4])\n",
        "      y = tf.placeholder(tf.float32,[None,1])\n",
        "      dropprob = tf.placeholder_with_default(1.0, shape=())\n",
        "\n",
        "      # Distinguish training and testing: training=1 for training , =0 for testing\n",
        "      training = tf.placeholder_with_default(0.0, shape=())\n",
        "\n",
        "    with tf.device('/cpu:0'):\n",
        "      \n",
        "      #Set up iterator for the data\n",
        "      dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "      dataset = dataset.shuffle(500).repeat().batch(batch_size)\n",
        "      \n",
        "                  \n",
        "      iterator = dataset.make_initializable_iterator()\n",
        "      data_X, data_y = iterator.get_next()      \n",
        "      data_y = tf.cast(data_y, tf.float32)\n",
        "      \n",
        "      \n",
        "   \n",
        "    with tf.device('/gpu:0'):\n",
        "      \n",
        "      conv_filt_shape = [filter_shape, num_input_channels, num_filters]\n",
        "\n",
        "      stdConv=tf.placeholder_with_default(logsampler(10**-7,10**-3),shape=()) \n",
        "      # initialise weights and bias for the filter\n",
        "      conv_weights = tf.Variable(tf.truncated_normal(conv_filt_shape, mean=0,stddev=stdConv), name='Conv1_W')\n",
        "      conv_bias = tf.Variable(tf.truncated_normal([num_filters]), name='Conv1_b')\n",
        "\n",
        "\n",
        "\n",
        "      if pooling=='max_pool':\n",
        "          W = tf.Variable(tf.truncated_normal([16,32], mean=0, stddev=0.3), name='W')\n",
        "          b = tf.Variable(tf.truncated_normal([32], mean=0, stddev=0.3), name='b')\n",
        "      else:\n",
        "          W = tf.Variable(tf.truncated_normal([32,32], mean=0, stddev=0.3), name='W')\n",
        "          b = tf.Variable(tf.truncated_normal([32], mean=0, stddev=0.3), name='b')     \n",
        "\n",
        "      if neuType == 'nohidden':\n",
        "          if pooling=='max_pool':\n",
        "              wdim1=16\n",
        "          else:\n",
        "              wdim1=32\n",
        "      else:\n",
        "          wdim1=32\n",
        "          \n",
        "      stdNeu=tf.placeholder_with_default(logsampler(10**-5,10**-2) ,shape=()) \n",
        "      wd1 = tf.Variable(tf.truncated_normal([wdim1,1], mean=0, stddev=stdNeu), name='w2')\n",
        "      bd1 = tf.Variable(tf.truncated_normal([1], mean=0, stddev=stdNeu), name='b2')\n",
        "\n",
        "\n",
        "      xconv = convolution(data_X,num_input_channels,num_filters,filter_shape,conv_weights,conv_bias,wd1,bd1,W,b,pooling,neuType,training,dropprob)\n",
        "\n",
        "\n",
        "      sig = tf.nn.sigmoid(xconv)\n",
        "      if neuType == 'hidden':\n",
        "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=data_y,logits=xconv))+ beta1*tf.norm(conv_weights,ord=1)+ beta2*tf.norm(wd1,ord=1)+ beta3*tf.norm(W,ord=1)\n",
        "      else:\n",
        "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=data_y,logits=xconv))+ beta1*tf.norm(conv_weights,ord=1)+ beta2*tf.norm(wd1,ord=1)\n",
        "\n",
        "      optimizer=tf.train.MomentumOptimizer(learning_rate,momentum_rate,use_nesterov=True).minimize(loss)\n",
        "\n",
        "    with tf.device('/cpu:0'):\n",
        "      #Set up iterator for the validation data\n",
        "      dataset_val = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "      dataset_val = dataset_val.batch(tf.cast(tf.size(y),tf.int64))\n",
        "                  \n",
        "      iterator_val = dataset_val.make_initializable_iterator()\n",
        "      data_XV, data_yV = iterator_val.get_next()      \n",
        "      data_yV = tf.cast(data_yV, tf.float32)\n",
        "    with tf.device('/gpu:0'):\n",
        "      xconvV = convolution(data_XV,num_input_channels,num_filters,filter_shape,conv_weights,conv_bias,wd1,bd1,W,b,pooling,neuType,training,dropprob)\n",
        "\n",
        "      sigV = tf.nn.sigmoid(xconvV)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kDzpFNLXA_ke",
        "colab_type": "code",
        "outputId": "3d688fca-73db-48c5-9f32-01fa873a3e55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3947
        }
      },
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "with tf.Session(graph=graph, config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
        "    dropoutList=[0.5,0.75,1.0] #list of possible dropout values\n",
        "    best_AUC=0\n",
        "\n",
        "    for iter in range(10):\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        sess.run(tf.local_variables_initializer())\n",
        "        beta_1=sess.run(beta1)\n",
        "        beta_2=sess.run(beta2)\n",
        "        beta_3=sess.run(beta3)\n",
        "        lea_r,mom_r,stdc,stdn=sess.run([learning_rate,momentum_rate,stdConv,stdNeu])\n",
        "                \n",
        "        \n",
        "        prob=random.choice(dropoutList)\n",
        "        \n",
        "        crossV=[0,1,2]\n",
        "    \n",
        "        CV_auc_list=[]\n",
        "        Avg_List=[]\n",
        "        for c in crossV:\n",
        "              sess.run(tf.global_variables_initializer())\n",
        "              sess.run(tf.local_variables_initializer())\n",
        "              sess.run([conv_weights,wd1,conv_bias,bd1], feed_dict={stdConv:stdc,stdNeu:stdn})\n",
        "              t=copy.copy(crossV)\n",
        "              t.remove(c)\n",
        "              traind=np.concatenate((data[t[0]], data[t[1]]), axis=0)\n",
        "              labeltrain=np.concatenate((label[t[0]], label[t[1]]), axis=0)\n",
        "\n",
        "              testd=data[c]\n",
        "              labeltest=label[c]\n",
        "\n",
        "\n",
        "\n",
        "              avg_cost=0\n",
        "              auc_list=[]\n",
        "              iterationSteps=0\n",
        "              sess.run(iterator.initializer, feed_dict = {x: traind, y: labeltrain})\n",
        "              try:\n",
        "\n",
        "                  while iterationSteps <=20000:\n",
        "                          iterationSteps+=1\n",
        "                      \n",
        "                          ### Training\n",
        "                          _,lss=sess.run([optimizer,loss], feed_dict= {training: 1, dropprob: prob, beta1:beta_1, \n",
        "                                                                       beta2: beta_2, beta3:beta_3, learning_rate:lea_r, momentum_rate:mom_r,stdConv:stdc,stdNeu:stdn})\n",
        "                         \n",
        "                          \n",
        "                          if iterationSteps % 4000==0:\n",
        "                                  ## Validation\n",
        "\n",
        "                                  sess.run(iterator_val.initializer, feed_dict = {x: testd, y: labeltest})\n",
        "\n",
        "                                  l,yl=sess.run([sigV, data_yV], feed_dict= {training: 0, dropprob: prob, beta1:beta_1, \n",
        "                                                                       beta2: beta_2, beta3:beta_3, learning_rate:lea_r, momentum_rate:mom_r,stdConv:stdc,stdNeu:stdn})\n",
        "                                  auc=metrics.roc_auc_score(yl, l)\n",
        "                                  print('AUC for the number of iterations',iterationSteps,'is:',auc)\n",
        "                                  auc_list.append(auc)\n",
        "\n",
        "\n",
        "              except tf.errors.OutOfRangeError:\n",
        "                  pass\n",
        "              print('===== Fold Done =====') \n",
        "              CV_auc_list.append(auc_list)\n",
        "              \n",
        "        print('The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps:' , CV_auc_list)\n",
        "        for i in range(len(auc_list)):\n",
        "                Avg_List.append(np.mean([CV_auc_list[j][i] for j in range(len(CV_auc_list))]))\n",
        "        print('The Average AUC for each Iteration Step of The Three Folds is:', Avg_List)\n",
        "        \n",
        "    \n",
        "        \n",
        "        maxlist=max(Avg_List)\n",
        "        if maxlist>best_AUC:\n",
        "          best_AUC=maxlist\n",
        "          \n",
        "          ind=Avg_List.index(maxlist)\n",
        "          \n",
        "          lr,mr,sc,sn,b1,b2,b3 = sess.run([learning_rate, momentum_rate,stdConv, stdNeu,beta1,beta2,beta3], feed_dict= {training: 0, dropprob: prob, beta1:beta_1, \n",
        "                                                                       beta2: beta_2, beta3:beta_3, learning_rate:lea_r, momentum_rate:mom_r,stdConv:stdc,stdNeu:stdn})\n",
        "          print( 'Best hyperparameters So far:')\n",
        "          print( 'Best Learning Rate', lr)\n",
        "          print( 'Best Momentum Rate', mr)\n",
        "          print( 'Best Learning Step', (ind+1)*4000)\n",
        "          print( 'Best Sigma Conv', sc)\n",
        "          print( 'Best Sigma NN', sn)\n",
        "          print( 'Best Dropout Prob', prob)\n",
        "          print( 'Best Beta 1', b1)\n",
        "          print( 'Best Beta 2', b2)\n",
        "          print( 'Best Beta 3', b3)\n",
        "          \n",
        "          save_LearningRate=lr\n",
        "          save_Momentum=mr\n",
        "          save_LearningStep=(ind+1)*4000\n",
        "          save_SigmaConv=sc\n",
        "          save_SigmaNeu=sn\n",
        "          save_Dropprob=prob\n",
        "          save_Beta1=b1\n",
        "          save_Beta2=b2\n",
        "          save_Beta3=b3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC for the number of iterations 4000 is: 0.5\n",
            "AUC for the number of iterations 8000 is: 0.5\n",
            "AUC for the number of iterations 12000 is: 0.5\n",
            "AUC for the number of iterations 16000 is: 0.5\n",
            "AUC for the number of iterations 20000 is: 0.5\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.5\n",
            "AUC for the number of iterations 8000 is: 0.5\n",
            "AUC for the number of iterations 12000 is: 0.5\n",
            "AUC for the number of iterations 16000 is: 0.5\n",
            "AUC for the number of iterations 20000 is: 0.5\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.5\n",
            "AUC for the number of iterations 8000 is: 0.5\n",
            "AUC for the number of iterations 12000 is: 0.5\n",
            "AUC for the number of iterations 16000 is: 0.5\n",
            "AUC for the number of iterations 20000 is: 0.5\n",
            "===== Fold Done =====\n",
            "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5, 0.5]]\n",
            "The Average AUC for each Iteration Step of The Three Folds is: [0.5, 0.5, 0.5, 0.5, 0.5]\n",
            "Best hyperparameters So far:\n",
            "Best Learning Rate 0.017687164\n",
            "Best Momentum Rate 0.9864146\n",
            "Best Learning Step 4000\n",
            "Best Sigma Conv 5.2392456e-06\n",
            "Best Sigma NN 0.0054370402\n",
            "Best Dropout Prob 1.0\n",
            "Best Beta 1 4.4971454e-10\n",
            "Best Beta 2 4.3065315e-10\n",
            "Best Beta 3 4.8584814e-10\n",
            "AUC for the number of iterations 4000 is: 0.6943339253996448\n",
            "AUC for the number of iterations 8000 is: 0.7137324556820952\n",
            "AUC for the number of iterations 12000 is: 0.8308076481036464\n",
            "AUC for the number of iterations 16000 is: 0.832002054818375\n",
            "AUC for the number of iterations 20000 is: 0.8299855466165151\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.5251085824547472\n",
            "AUC for the number of iterations 8000 is: 0.7098065543051594\n",
            "AUC for the number of iterations 12000 is: 0.7406542462967027\n",
            "AUC for the number of iterations 16000 is: 0.8097482140929055\n",
            "AUC for the number of iterations 20000 is: 0.8355617552915443\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.5717726707101648\n",
            "AUC for the number of iterations 8000 is: 0.6815280593819888\n",
            "AUC for the number of iterations 12000 is: 0.7726811524839666\n",
            "AUC for the number of iterations 16000 is: 0.8252169826918558\n",
            "AUC for the number of iterations 20000 is: 0.8229160176475194\n",
            "===== Fold Done =====\n",
            "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.6943339253996448, 0.7137324556820952, 0.8308076481036464, 0.832002054818375, 0.8299855466165151], [0.5251085824547472, 0.7098065543051594, 0.7406542462967027, 0.8097482140929055, 0.8355617552915443], [0.5717726707101648, 0.6815280593819888, 0.7726811524839666, 0.8252169826918558, 0.8229160176475194]]\n",
            "The Average AUC for each Iteration Step of The Three Folds is: [0.5970717261881856, 0.7016890231230811, 0.7813810156281052, 0.8223224172010454, 0.829487773185193]\n",
            "Best hyperparameters So far:\n",
            "Best Learning Rate 0.00067280565\n",
            "Best Momentum Rate 0.9702572\n",
            "Best Learning Step 20000\n",
            "Best Sigma Conv 0.00017863222\n",
            "Best Sigma NN 0.008772475\n",
            "Best Dropout Prob 1.0\n",
            "Best Beta 1 2.7465255e-09\n",
            "Best Beta 2 1.7544446e-09\n",
            "Best Beta 3 4.927341e-05\n",
            "AUC for the number of iterations 4000 is: 0.8274361787343713\n",
            "AUC for the number of iterations 8000 is: 0.8304633789572669\n",
            "AUC for the number of iterations 12000 is: 0.8313481698185492\n",
            "AUC for the number of iterations 16000 is: 0.8164286211820431\n",
            "AUC for the number of iterations 20000 is: 0.8242802911573155\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.6780820176309343\n",
            "AUC for the number of iterations 8000 is: 0.6788752703677001\n",
            "AUC for the number of iterations 12000 is: 0.6726034363255767\n",
            "AUC for the number of iterations 16000 is: 0.6607041228244326\n",
            "AUC for the number of iterations 20000 is: 0.6744017080620949\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.7923938146662373\n",
            "AUC for the number of iterations 8000 is: 0.797182314191982\n",
            "AUC for the number of iterations 12000 is: 0.7940962607795192\n",
            "AUC for the number of iterations 16000 is: 0.797799629297667\n",
            "AUC for the number of iterations 20000 is: 0.7927312756163143\n",
            "===== Fold Done =====\n",
            "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.8274361787343713, 0.8304633789572669, 0.8313481698185492, 0.8164286211820431, 0.8242802911573155], [0.6780820176309343, 0.6788752703677001, 0.6726034363255767, 0.6607041228244326, 0.6744017080620949], [0.7923938146662373, 0.797182314191982, 0.7940962607795192, 0.797799629297667, 0.7927312756163143]]\n",
            "The Average AUC for each Iteration Step of The Three Folds is: [0.7659706703438477, 0.7688403211723163, 0.766015955641215, 0.758310791101381, 0.7638044249452415]\n",
            "AUC for the number of iterations 4000 is: 0.8078727405704733\n",
            "AUC for the number of iterations 8000 is: 0.801227841047609\n",
            "AUC for the number of iterations 12000 is: 0.8009121303938983\n",
            "AUC for the number of iterations 16000 is: 0.8002417023647824\n",
            "AUC for the number of iterations 20000 is: 0.799314944450249\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.8090975901138593\n",
            "AUC for the number of iterations 8000 is: 0.8121521791375401\n",
            "AUC for the number of iterations 12000 is: 0.8112302296340415\n",
            "AUC for the number of iterations 16000 is: 0.8115668613662408\n",
            "AUC for the number of iterations 20000 is: 0.8102724052537538\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.793306125290427\n",
            "AUC for the number of iterations 8000 is: 0.7892071669117711\n",
            "AUC for the number of iterations 12000 is: 0.7889643829894619\n",
            "AUC for the number of iterations 16000 is: 0.7877727403256263\n",
            "AUC for the number of iterations 20000 is: 0.7869373547864982\n",
            "===== Fold Done =====\n",
            "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.8078727405704733, 0.801227841047609, 0.8009121303938983, 0.8002417023647824, 0.799314944450249], [0.8090975901138593, 0.8121521791375401, 0.8112302296340415, 0.8115668613662408, 0.8102724052537538], [0.793306125290427, 0.7892071669117711, 0.7889643829894619, 0.7877727403256263, 0.7869373547864982]]\n",
            "The Average AUC for each Iteration Step of The Three Folds is: [0.80342548532492, 0.8008623956989734, 0.8003689143391339, 0.7998604346855499, 0.7988415681635003]\n",
            "AUC for the number of iterations 4000 is: 0.8234473931668583\n",
            "AUC for the number of iterations 8000 is: 0.8229270713614043\n",
            "AUC for the number of iterations 12000 is: 0.829789642322293\n",
            "AUC for the number of iterations 16000 is: 0.8337296694876886\n",
            "AUC for the number of iterations 20000 is: 0.8372817190819489\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.8248795753529148\n",
            "AUC for the number of iterations 8000 is: 0.8304811064787242\n",
            "AUC for the number of iterations 12000 is: 0.8273868112807331\n",
            "AUC for the number of iterations 16000 is: 0.8324651961450181\n",
            "AUC for the number of iterations 20000 is: 0.8345913921193693\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.7945365785741012\n",
            "AUC for the number of iterations 8000 is: 0.7977230522899137\n",
            "AUC for the number of iterations 12000 is: 0.8037731580183959\n",
            "AUC for the number of iterations 16000 is: 0.8000194923292463\n",
            "AUC for the number of iterations 20000 is: 0.7948160846524013\n",
            "===== Fold Done =====\n",
            "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.8234473931668583, 0.8229270713614043, 0.829789642322293, 0.8337296694876886, 0.8372817190819489], [0.8248795753529148, 0.8304811064787242, 0.8273868112807331, 0.8324651961450181, 0.8345913921193693], [0.7945365785741012, 0.7977230522899137, 0.8037731580183959, 0.8000194923292463, 0.7948160846524013]]\n",
            "The Average AUC for each Iteration Step of The Three Folds is: [0.8142878490312914, 0.8170437433766807, 0.8203165372071406, 0.8220714526539844, 0.8222297319512398]\n",
            "AUC for the number of iterations 4000 is: 0.8171162887890502\n",
            "AUC for the number of iterations 8000 is: 0.8292930031692962\n",
            "AUC for the number of iterations 12000 is: 0.8298424058788703\n",
            "AUC for the number of iterations 16000 is: 0.8297006582384285\n",
            "AUC for the number of iterations 20000 is: 0.8359934524431442\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.7862205643152949\n",
            "AUC for the number of iterations 8000 is: 0.784281405319931\n",
            "AUC for the number of iterations 12000 is: 0.7883636528287166\n",
            "AUC for the number of iterations 16000 is: 0.7865080857792685\n",
            "AUC for the number of iterations 20000 is: 0.7958534911827913\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.7779305063654637\n",
            "AUC for the number of iterations 8000 is: 0.7853048722121183\n",
            "AUC for the number of iterations 12000 is: 0.7914052751116023\n",
            "AUC for the number of iterations 16000 is: 0.7890769859985902\n",
            "AUC for the number of iterations 20000 is: 0.7855436532453859\n",
            "===== Fold Done =====\n",
            "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.8171162887890502, 0.8292930031692962, 0.8298424058788703, 0.8297006582384285, 0.8359934524431442], [0.7862205643152949, 0.784281405319931, 0.7883636528287166, 0.7865080857792685, 0.7958534911827913], [0.7779305063654637, 0.7853048722121183, 0.7914052751116023, 0.7890769859985902, 0.7855436532453859]]\n",
            "The Average AUC for each Iteration Step of The Three Folds is: [0.7937557864899363, 0.7996264269004486, 0.8032037779397297, 0.8017619100054292, 0.8057968656237738]\n",
            "AUC for the number of iterations 4000 is: 0.8246040121199456\n",
            "AUC for the number of iterations 8000 is: 0.8355678612475186\n",
            "AUC for the number of iterations 12000 is: 0.840574652596385\n",
            "AUC for the number of iterations 16000 is: 0.840197471528576\n",
            "AUC for the number of iterations 20000 is: 0.8405652491902622\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.8305403174404147\n",
            "AUC for the number of iterations 8000 is: 0.8345405403522704\n",
            "AUC for the number of iterations 12000 is: 0.8388946358351707\n",
            "AUC for the number of iterations 16000 is: 0.8395264516263858\n",
            "AUC for the number of iterations 20000 is: 0.8420462263460915\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.7989039045572022\n",
            "AUC for the number of iterations 8000 is: 0.8054684685468643\n",
            "AUC for the number of iterations 12000 is: 0.8051741691829756\n",
            "AUC for the number of iterations 16000 is: 0.8046576224579478\n",
            "AUC for the number of iterations 20000 is: 0.8033580758286416\n",
            "===== Fold Done =====\n",
            "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.8246040121199456, 0.8355678612475186, 0.840574652596385, 0.840197471528576, 0.8405652491902622], [0.8305403174404147, 0.8345405403522704, 0.8388946358351707, 0.8395264516263858, 0.8420462263460915], [0.7989039045572022, 0.8054684685468643, 0.8051741691829756, 0.8046576224579478, 0.8033580758286416]]\n",
            "The Average AUC for each Iteration Step of The Three Folds is: [0.8180160780391875, 0.8251922900488844, 0.8282144858715105, 0.8281271818709698, 0.8286565171216651]\n",
            "AUC for the number of iterations 4000 is: 0.811903319054087\n",
            "AUC for the number of iterations 8000 is: 0.8120903423536378\n",
            "AUC for the number of iterations 12000 is: 0.8139358478737855\n",
            "AUC for the number of iterations 16000 is: 0.8099226831052135\n",
            "AUC for the number of iterations 20000 is: 0.8093445477658203\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.8195890759258678\n",
            "AUC for the number of iterations 8000 is: 0.8138121758635223\n",
            "AUC for the number of iterations 12000 is: 0.8142478988816093\n",
            "AUC for the number of iterations 16000 is: 0.8149859461040929\n",
            "AUC for the number of iterations 20000 is: 0.814467327739639\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.6625989192199587\n",
            "AUC for the number of iterations 8000 is: 0.6630900563015046\n",
            "AUC for the number of iterations 12000 is: 0.6681222099428283\n",
            "AUC for the number of iterations 16000 is: 0.6683334928687661\n",
            "AUC for the number of iterations 20000 is: 0.6621685216286536\n",
            "===== Fold Done =====\n",
            "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.811903319054087, 0.8120903423536378, 0.8139358478737855, 0.8099226831052135, 0.8093445477658203], [0.8195890759258678, 0.8138121758635223, 0.8142478988816093, 0.8149859461040929, 0.814467327739639], [0.6625989192199587, 0.6630900563015046, 0.6681222099428283, 0.6683334928687661, 0.6621685216286536]]\n",
            "The Average AUC for each Iteration Step of The Three Folds is: [0.7646971047333045, 0.7629975248395549, 0.7654353188994077, 0.7644140406926908, 0.761993465711371]\n",
            "AUC for the number of iterations 4000 is: 0.7928628147528993\n",
            "AUC for the number of iterations 8000 is: 0.8211573155016891\n",
            "AUC for the number of iterations 12000 is: 0.8091601365235259\n",
            "AUC for the number of iterations 16000 is: 0.810733988089019\n",
            "AUC for the number of iterations 20000 is: 0.8069689687597952\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.830071680093623\n",
            "AUC for the number of iterations 8000 is: 0.8438471103309195\n",
            "AUC for the number of iterations 12000 is: 0.8396098694224146\n",
            "AUC for the number of iterations 16000 is: 0.8351040893876542\n",
            "AUC for the number of iterations 20000 is: 0.8377825146547131\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.8205612746591018\n",
            "AUC for the number of iterations 8000 is: 0.8285451238720121\n",
            "AUC for the number of iterations 12000 is: 0.8269829529138422\n",
            "AUC for the number of iterations 16000 is: 0.8294946787681544\n",
            "AUC for the number of iterations 20000 is: 0.8233622527563371\n",
            "===== Fold Done =====\n",
            "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.7928628147528993, 0.8211573155016891, 0.8091601365235259, 0.810733988089019, 0.8069689687597952], [0.830071680093623, 0.8438471103309195, 0.8396098694224146, 0.8351040893876542, 0.8377825146547131], [0.8205612746591018, 0.8285451238720121, 0.8269829529138422, 0.8294946787681544, 0.8233622527563371]]\n",
            "The Average AUC for each Iteration Step of The Three Folds is: [0.8144985898352081, 0.8311831832348736, 0.8252509862865942, 0.8251109187482758, 0.8227045787236151]\n",
            "Best hyperparameters So far:\n",
            "Best Learning Rate 0.0008793039\n",
            "Best Momentum Rate 0.98245007\n",
            "Best Learning Step 8000\n",
            "Best Sigma Conv 4.271772e-05\n",
            "Best Sigma NN 1.0823152e-05\n",
            "Best Dropout Prob 0.75\n",
            "Best Beta 1 3.5713121e-09\n",
            "Best Beta 2 8.821362e-09\n",
            "Best Beta 3 1.699598e-06\n",
            "AUC for the number of iterations 4000 is: 0.744097098875074\n",
            "AUC for the number of iterations 8000 is: 0.7815539999303452\n",
            "AUC for the number of iterations 12000 is: 0.7819842928290321\n",
            "AUC for the number of iterations 16000 is: 0.7802758332462648\n",
            "AUC for the number of iterations 20000 is: 0.7782349458433462\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.8154948120748566\n",
            "AUC for the number of iterations 8000 is: 0.8323866545458345\n",
            "AUC for the number of iterations 12000 is: 0.820772250260354\n",
            "AUC for the number of iterations 16000 is: 0.8188639157950465\n",
            "AUC for the number of iterations 20000 is: 0.8177086054425322\n",
            "===== Fold Done =====\n",
            "AUC for the number of iterations 4000 is: 0.8252206375035895\n",
            "AUC for the number of iterations 8000 is: 0.8289809166615905\n",
            "AUC for the number of iterations 12000 is: 0.8291298937494017\n",
            "AUC for the number of iterations 16000 is: 0.827193887762472\n",
            "AUC for the number of iterations 20000 is: 0.8250622623284631\n",
            "===== Fold Done =====\n",
            "The Cross Validation AUC for The Three Folds in 5 Different Iteration Steps: [[0.744097098875074, 0.7815539999303452, 0.7819842928290321, 0.7802758332462648, 0.7782349458433462], [0.8154948120748566, 0.8323866545458345, 0.820772250260354, 0.8188639157950465, 0.8177086054425322], [0.8252206375035895, 0.8289809166615905, 0.8291298937494017, 0.827193887762472, 0.8250622623284631]]\n",
            "The Average AUC for each Iteration Step of The Three Folds is: [0.7949375161511734, 0.8143071903792567, 0.8106288122795959, 0.8087778789345945, 0.8070019378714471]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8Y02tdVhgqpm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "graph2=tf.Graph()\n",
        "with graph2.as_default():\n",
        "    \n",
        "    num_input_channels=4\n",
        "    num_filters=16\n",
        "    filter_shape=24\n",
        "    pooling='max_pool'\n",
        "    neuType='hidden'\n",
        "    \n",
        "    beta1=save_Beta1\n",
        "    beta2=save_Beta2\n",
        "    beta3=save_Beta3\n",
        "\n",
        "    \n",
        "    \n",
        "    learning_rate= save_LearningRate\n",
        "    momentum_rate= save_Momentum\n",
        "    batch_size=64\n",
        "    \n",
        "    \n",
        "    with tf.device('/gpu:0'):\n",
        "    \n",
        "      x = tf.placeholder(tf.float32, [None, 147, 4],name='X')\n",
        "      y = tf.placeholder(tf.float32,[None,1],name='y')\n",
        "\n",
        "\n",
        "    with tf.device('/cpu:0'):\n",
        "      \n",
        "      #Set up iterator for the data\n",
        "      dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "      dataset = dataset.shuffle(500).repeat().batch(batch_size)\n",
        "      iterator = dataset.make_initializable_iterator()\n",
        "      data_X, data_y = iterator.get_next()\n",
        "      data_y = tf.cast(data_y, tf.float32)\n",
        "\n",
        "      dropprob = tf.placeholder_with_default(0.5, shape=(),name='prob')\n",
        "\n",
        "      # Distinguish training and testing: training=1 for training , =0 for testing\n",
        "      training = tf.placeholder_with_default(0.0, shape=(),name='training')\n",
        "      \n",
        "   \n",
        "    with tf.device('/gpu:0'):\n",
        "      \n",
        "      conv_filt_shape = [filter_shape, num_input_channels, num_filters]\n",
        "\n",
        "      stdConv=save_SigmaConv\n",
        "      # initialise weights and bias for the filter\n",
        "      conv_weights = tf.Variable(tf.truncated_normal(conv_filt_shape, mean=0,stddev=stdConv), name='Conv1_W')\n",
        "      conv_bias = tf.Variable(tf.truncated_normal([num_filters]), name='Conv1_b')\n",
        "\n",
        "\n",
        "\n",
        "      if pooling=='max_pool':\n",
        "          W = tf.Variable(tf.truncated_normal([16,32], mean=0, stddev=0.3), name='W')\n",
        "          b = tf.Variable(tf.truncated_normal([32], mean=0, stddev=0.3), name='b')\n",
        "      else:\n",
        "          W = tf.Variable(tf.truncated_normal([32,32], mean=0, stddev=0.3), name='W')\n",
        "          b = tf.Variable(tf.truncated_normal([32], mean=0, stddev=0.3), name='b')     \n",
        "\n",
        "      if neuType == 'nohidden':\n",
        "          if pooling=='max_pool':\n",
        "              wdim1=16\n",
        "          else:\n",
        "              wdim1=32\n",
        "      else:\n",
        "          wdim1=32\n",
        "      stdNeu=save_SigmaNeu\n",
        "      wd1 = tf.Variable(tf.truncated_normal([wdim1,1], mean=0, stddev=stdNeu), name='w2')\n",
        "      bd1 = tf.Variable(tf.truncated_normal([1], mean=0, stddev=stdNeu), name='b2')\n",
        "\n",
        "\n",
        "      xconv = convolution(data_X,num_input_channels,num_filters,filter_shape,conv_weights,conv_bias,wd1,bd1,W,b,pooling,neuType,training,dropprob)\n",
        "\n",
        "      sig = tf.nn.sigmoid(xconv)\n",
        "      if neuType == 'hidden':\n",
        "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=data_y,logits=xconv))+ beta1*tf.norm(conv_weights,ord=1)+ beta2*tf.norm(wd1,ord=1)+ beta3*tf.norm(W,ord=1)\n",
        "      else:\n",
        "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=data_y,logits=xconv))+ beta1*tf.norm(conv_weights,ord=1)+ beta2*tf.norm(wd1,ord=1)\n",
        "\n",
        "      optimizer=tf.train.MomentumOptimizer(learning_rate,momentum_rate,use_nesterov=True).minimize(loss)\n",
        "    with tf.device('/cpu:0'):\n",
        "      \n",
        "      #Set up iterator for the validation data\n",
        "      dataset_val = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "      dataset_val = dataset_val.batch(tf.cast(tf.size(y),tf.int64))\n",
        "                  \n",
        "      iterator_val = dataset_val.make_initializable_iterator()\n",
        "      data_XV, data_yV = iterator_val.get_next()      \n",
        "      data_yV = tf.cast(data_yV, tf.float32)\n",
        "      \n",
        "      \n",
        "      data_XV = tf.placeholder_with_default(data_XV, shape=None, name='input')\n",
        "      data_yV = tf.placeholder_with_default(data_yV, shape=None,name='label')\n",
        "      \n",
        "      \n",
        "    with tf.device('/gpu:0'):\n",
        "      xconvV = convolution(data_XV,num_input_channels,num_filters,filter_shape,conv_weights,conv_bias,wd1,bd1,W,b,pooling,neuType,training,dropprob)\n",
        "\n",
        "      sigV = tf.nn.sigmoid(xconvV, name='Conv_V')\n",
        "  \n",
        "    saver = tf.train.Saver()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aUuRMPtdBCqO",
        "colab_type": "code",
        "outputId": "58e67c51-8d56-4bc2-d1f3-472e443a4d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "with tf.Session(graph=graph2, config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
        "    auc_list=[]\n",
        "    best_auc=0\n",
        "    for iter in range(6):\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        sess.run(tf.local_variables_initializer())\n",
        "        \n",
        "\n",
        "        prob=save_Dropprob\n",
        "        iterationSteps=0\n",
        "        sess.run(iterator.initializer, feed_dict = {x: data_all, y: label_all})\n",
        "        try:\n",
        "\n",
        "            while iterationSteps <=save_LearningStep:\n",
        "                  iterationSteps+=1\n",
        "              \n",
        "                  ### Training\n",
        "                  _,lss=sess.run([optimizer,loss], feed_dict= {training: 1, dropprob: prob})\n",
        "                  \n",
        "        except tf.errors.OutOfRangeError:\n",
        "            pass\n",
        "          \n",
        "        ## Validation\n",
        "        sess.run(iterator_val.initializer, feed_dict = {x: data_all, y: label_all})\n",
        "        l,yl=sess.run([sigV,data_yV], feed_dict= {training: 0, dropprob: prob})\n",
        "\n",
        "        auc=metrics.roc_auc_score(yl, l)\n",
        "        print('AUC of Model Num',iter,' is : ', auc)\n",
        "        \n",
        "        if auc > best_auc:\n",
        "          best_auc=auc\n",
        "          print('Best AUC So Far is : ', best_auc)\n",
        "          ##save model\n",
        "          save_path = saver.save(sess, \"/content/drive/My Drive/replicate 2\")\n",
        "          print('Model Saved!')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC of Model Num 0  is :  0.9069409684414349\n",
            "Best AUC So Far is :  0.9069409684414349\n",
            "Model Saved!\n",
            "AUC of Model Num 1  is :  0.9249102489660717\n",
            "Best AUC So Far is :  0.9249102489660717\n",
            "Model Saved!\n",
            "AUC of Model Num 2  is :  0.8904167074192125\n",
            "AUC of Model Num 3  is :  0.90750025844336\n",
            "AUC of Model Num 4  is :  0.9095677472900588\n",
            "AUC of Model Num 5  is :  0.9145899246707245\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}